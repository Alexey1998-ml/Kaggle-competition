{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Alexey1998-ml/example/blob/master/catch_me.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "APqRITJb9qDF",
    "outputId": "9d66a4f9-450b-4a60-858b-40d79e33c9d5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HXtJ78p4Jka"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,\\\n",
    "learning_curve, TimeSeriesSplit\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import clear_output\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fixb8ixl5k00"
   },
   "outputs": [],
   "source": [
    "colab = False\n",
    "if colab:\n",
    "    PATH_TO_TRAIN = 'drive/My Drive/catch_me_test_sessions.csv'\n",
    "    PATH_TO_TEST = 'drive/My Drive/catch_me_train_sessions.csv'\n",
    "else:\n",
    "    PATH_TO_TRAIN = 'catch_me_test_sessions.csv'\n",
    "    PATH_TO_TEST = 'catch_me_train_sessions.csv'\n",
    "PREDICT_FILENAME = 'catch_me_preds.csv'\n",
    "test = pd.read_csv(PATH_TO_TRAIN)\n",
    "data = pd.read_csv(PATH_TO_TEST)\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "sites = ['site%s' % i for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc (model, data, predict = True, target = 'target', prob = 1):\n",
    "    data = data.sample(int(data.shape[0] * prob))\n",
    "    batch = trainer.make_batch(data, predict = predict)\n",
    "    roc_auc = roc_auc_score(data[target],\n",
    "                            model(torch.tensor(batch['sites'], dtype=torch.long).cuda(),\n",
    "                                 torch.tensor(batch['cat'], dtype=torch.long).float().cuda()).cpu().data.numpy())\n",
    "    return roc_auc\n",
    "\n",
    "class MyAttention(nn.Module):\n",
    "    def __init__(self, hid_size):\n",
    "        \n",
    "        super(MyAttention, self).__init__()\n",
    "        self.hid_size = hid_size\n",
    "        self.relu = nn.ReLU()\n",
    "        att_weights = nn.Parameter(torch.Tensor(1, hid_size), requires_grad = True)\n",
    "        std = 1 / np.sqrt(hid_size)\n",
    "        self.att_weights = nn.init.uniform_(att_weights, -std, std)\n",
    "  \n",
    "    def forward (self, input):\n",
    "        batch_size = input.size(0)\n",
    "\n",
    "        weights = torch.bmm(input,\n",
    "                            self.att_weights            # 1, hid_size\n",
    "                            .permute(1,0)               # hid_size , 1\n",
    "                            .unsqueeze(0)               # 1, hid_size, 1\n",
    "                            .repeat(batch_size, 1,1)    # batch_size , hid_size, 1\n",
    "                            )    \n",
    "        attention = torch.softmax(self.relu(weights.squeeze()), dim = -1)\n",
    "        weights = torch.mul(input, attention.unsqueeze(-1))\n",
    "        representation = weights.sum(1)\n",
    "        return representation\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIk-VMGt6GyX"
   },
   "outputs": [],
   "source": [
    "class Prepare:\n",
    "    def __init__(self, train, test, target_column : str = 'target', **kwargs):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.target_column = target_column\n",
    "        self.target = train[target_column]\n",
    "        self.unknown_idx = -1\n",
    "        self.pad_idx = 0\n",
    "        self.test_size = 0.15\n",
    "        self.batch_size = 1024\n",
    "        self.dropout = 0.5\n",
    "\n",
    "    def prepare_df (self):\n",
    "        train = self.train\n",
    "        test = self.test\n",
    "        train[times] = train[times].apply(pd.to_datetime)\n",
    "        test[times] = test[times].apply(pd.to_datetime)\n",
    "        train[sites] = train[sites].fillna(self.pad_idx).astype(int)\n",
    "        train = train.sort_values('time1')\n",
    "        train = self._create_cat_features(train)\n",
    "        test = self._create_cat_features(test)\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.sites_to_id = False\n",
    "    \n",
    "    def _create_cat_features(self, df):\n",
    "        cat = 'cat_'\n",
    "        df[f'{cat}hour'] = df['time1'].apply(lambda time: time.hour)\n",
    "        df[f'{cat}morning'] = ((df[f'{cat}hour'] >= 7) & (df[f'{cat}hour'] <= 11)).astype('int')\n",
    "        df[f'{cat}day'] = ((df[f'{cat}hour'] >= 12) & (df[f'{cat}hour'] <= 18)).astype('int')\n",
    "        df[f'{cat}evening'] = ((df[f'{cat}hour'] >= 19) & (df[f'{cat}hour'] <= 23)).astype('int')\n",
    "        df[f'{cat}day_of_week'] = df['time1'].apply(lambda t: t.weekday()).astype('int')\n",
    "        df = pd.concat([df, pd.get_dummies(df['cat_day_of_week'],\n",
    "                                                 prefix = 'cat_day_of_week')], axis = 1)\n",
    "        df.drop('cat_day_of_week', axis = 1, inplace = True)\n",
    "        self.cat_columns = list(filter(lambda col: col[:4] == 'cat_', df.columns))\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def _get_known_sites(self, train, number_sites = 5000):\n",
    "        counter = Counter()\n",
    "        alice_sites = Counter()\n",
    "        for site in sites:\n",
    "            for num_site in train[site]:\n",
    "                counter.update({num_site})\n",
    "        for site in sites:\n",
    "            for num_site in train[train['target'] == 1][site]:\n",
    "                alice_sites.update({num_site})\n",
    "        known_sites = [site for site, counts in dict(counter.most_common(number_sites)).items()]\n",
    "        known_sites += [site for site, counts in alice_sites.items()]\n",
    "        known_sites += [self.pad_idx, self.unknown_idx]\n",
    "        known_sites = set(known_sites)\n",
    "        sites_to_id = {site : inx for inx, site in enumerate(known_sites)}\n",
    "        self.id_unknown_idx = sites_to_id[self.unknown_idx]\n",
    "        self.sites_to_id = sites_to_id\n",
    "        return sites_to_id\n",
    "\n",
    "    def get_df_for_train(self):\n",
    "        train_df, valid_df, train_target, valid_target = train_test_split(self.train, self.target, random_state = 42,\n",
    "                                                                          shuffle = False, test_size = self.test_size)\n",
    "        sites_to_id = self._get_known_sites(train_df)\n",
    "        self.sites_to_id = sites_to_id\n",
    "        sites_to_id = self._get_known_sites(train_df)\n",
    "        train_df[sites] = train_df[sites].applymap(lambda num_site: sites_to_id[num_site] if num_site in sites_to_id \n",
    "                                                   else sites_to_id[self.unknown_idx])\n",
    "        valid_df[sites] = valid_df[sites].applymap(lambda num_site: sites_to_id[num_site] if num_site in sites_to_id \n",
    "                                                   else sites_to_id[self.unknown_idx])\n",
    "        return train_df, valid_df\n",
    "    \n",
    "    def _get_df_for_test(self):\n",
    "        test = self.test\n",
    "        sites_to_id = self.sites_to_id\n",
    "        test[sites] = test[sites].applymap(lambda num_site: sites_to_id[num_site] if num_site in sites_to_id \n",
    "                                           else sites_to_id[self.unknown_idx])\n",
    "        self.test = test\n",
    "        return test\n",
    "    \n",
    "    def get_train_df(self):\n",
    "        train = self.train\n",
    "        sites_to_id = self._get_known_sites(train)\n",
    "        self.sites_to_id = sites_to_id\n",
    "        train[sites] = train[sites].applymap(lambda num_site: sites_to_id[num_site] if num_site in sites_to_id \n",
    "                                           else sites_to_id[self.unknown_idx])\n",
    "        self.train = train\n",
    "        return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7syXo7AsyFpM"
   },
   "outputs": [],
   "source": [
    "class TrainNN(Prepare):\n",
    "    \n",
    "    def make_batch (self, df, dropout = 0, predict = False, **kwargs):\n",
    "        if 'is_test' in kwargs:\n",
    "            is_test = kwargs['is_test']\n",
    "        else:\n",
    "            is_test = False\n",
    "        if self.dropout:\n",
    "            dropout = self.dropout\n",
    "            \n",
    "        batch = {}\n",
    "        batch['sites'] = df[sites].values\n",
    "        if dropout > 0 and not predict:\n",
    "            batch['sites'] = self._apply_word_dropout(batch['sites'], dropout, self.id_unknown_idx)\n",
    "            \n",
    "        if not is_test:\n",
    "            batch[self.target_column] = df[self.target_column].values\n",
    "        batch['cat'] = df[self.cat_columns].values\n",
    "        return batch\n",
    "\n",
    "    def _apply_word_dropout (self, matrix, keep_prop, replace_with = -1, pad_ix = 0):\n",
    "        dropout_mask = np.random.choice(2, matrix.shape, p = [1 - keep_prop, keep_prop])\n",
    "        dropout_mask &= matrix !=  pad_ix\n",
    "        return np.choose (dropout_mask, [matrix, np.full_like(matrix, replace_with)])\n",
    "    \n",
    "    def iterable_minibatches (self, data, shuffle = True, **kwargs):\n",
    "        indecses = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indecses = np.random.permutation(indecses)\n",
    "        for start in range(0, len(indecses), self.batch_size):\n",
    "            batch = self.make_batch(data.iloc[indecses[start : start + self.batch_size]], **kwargs)\n",
    "            target = batch.pop(self.target_column)\n",
    "            yield batch, target\n",
    "    \n",
    "    def make_predictions_file (self, model):\n",
    "        test = self._get_df_for_test()\n",
    "        batch = self.make_batch(test, predict = True, is_test = True)\n",
    "        input_site = torch.tensor(batch['sites'], dtype=torch.long).cuda()\n",
    "        input_cat = torch.tensor(batch['cat'], dtype=torch.long).float().cuda()\n",
    "        predictions = model(input_site, input_cat).cpu().data.numpy()\n",
    "        series_preds = pd.Series(predictions[:,0], index = range (1,predictions[:,0].shape[0] + 1),\n",
    "                  name = 'target')\n",
    "        series_preds.to_csv(PREDICT_FILENAME, header = True, index_label = 'session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjsxINZHufkH"
   },
   "outputs": [],
   "source": [
    "trainer = TrainNN(data, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9dNFt6ay1aC"
   },
   "outputs": [],
   "source": [
    "trainer.prepare_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v7Snyg7szDVJ"
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = trainer.get_df_for_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainer.get_train_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wz7apoKXyMLP"
   },
   "outputs": [],
   "source": [
    "class Reorder(nn.Module):\n",
    "    def forward (self, input):\n",
    "        return input.permute(0, 2, 1)\n",
    "\n",
    "class Flatten (nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcVmov9A6NtE"
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, n_tokens = len(trainer.sites_to_id), hid_size = 64, \n",
    "                   len_sequence = 10, len_cat = len(trainer.cat_columns), rnn_dim = 32,\n",
    "                num_direction = 2):\n",
    "        super(NN, self).__init__()\n",
    "        self.emb = nn.Embedding(n_tokens, hid_size)\n",
    "        self.lstm = nn.LSTM(input_size = hid_size, hidden_size = rnn_dim, bidirectional = True)\n",
    "        self.att = MyAttention(rnn_dim * num_direction)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_cat = nn.Linear(len_cat, len_cat)\n",
    "        self.fc = nn.Linear(len_cat + rnn_dim * num_direction, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.batchnorm = nn.BatchNorm1d(len_cat + rnn_dim * num_direction)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_site, input_cat):\n",
    "        emb = self.emb(input_site)\n",
    "        lstm = self.lstm(emb)\n",
    "        att = self.att(lstm[0])\n",
    "        cat = self.fc_cat(input_cat)\n",
    "        combine = torch.cat([att.view(att.size(0), -1),\n",
    "                             cat.view(cat.size(0), -1)], dim = 1)\n",
    "        combine = self.batchnorm(combine)\n",
    "        combine = self.dropout(combine)\n",
    "        out = self.fc(combine)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "XKg_38X568AF",
    "outputId": "101d3516-e363-4aba-8e7c-472f36524844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (emb): Embedding(5364, 64)\n",
       "  (lstm): LSTM(64, 32, bidirectional=True)\n",
       "  (att): MyAttention(\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (fc_cat): Linear(in_features=11, out_features=11, bias=True)\n",
       "  (fc): Linear(in_features=75, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (batchnorm): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NN()\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGlbDX6h-jqt"
   },
   "outputs": [],
   "source": [
    "batch, target = next(trainer.iterable_minibatches(train_df))\n",
    "input_site = torch.tensor(batch['sites'], dtype=torch.long).cuda()\n",
    "input_cat = torch.tensor(batch['cat'], dtype=torch.long).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 631
    },
    "colab_type": "code",
    "id": "8O3YSw9A7N3b",
    "outputId": "da67a444-231d-400e-cb32-d2d82ccced1a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30af0550005c4947b58b28b72915ff40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e04d181da9a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mhistory_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mhistory_train_roc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mhistory_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mhistory_train_roc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-712fcf2b550b>\u001b[0m in \u001b[0;36mroc_auc\u001b[1;34m(model, data, predict, target, prob)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'target'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     roc_auc = roc_auc_score(data[target],\n\u001b[0;32m      5\u001b[0m                             model(torch.tensor(batch['sites'], dtype=torch.long).cuda(),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   4969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4970\u001b[0m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4971\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4973\u001b[0m     _shared_docs[\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3599\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3601\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3603\u001b[0m         new_data = self._data.take(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5239\u001b[0m         \"\"\"\n\u001b[0;32m   5240\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5241\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5242\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5249\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5250\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5252\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    930\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1911\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m         merged_blocks = _merge_blocks(\n\u001b[1;32m-> 1913\u001b[1;33m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_can_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1914\u001b[0m         )\n\u001b[0;32m   1915\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   3318\u001b[0m         \u001b[1;31m# combination of those slices is a slice, too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3319\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3320\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3322\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \"\"\"\n\u001b[0;32m    282\u001b[0m     \u001b[0m_warn_for_nonsequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_train = []\n",
    "history_val = []\n",
    "history_train_roc = []\n",
    "epochs = 300\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_function = nn.BCELoss().to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for idx, (batch, target) in tqdm_notebook(enumerate(trainer.iterable_minibatches(train_df))):\n",
    "        input_site = torch.tensor(batch['sites'], dtype=torch.long).cuda()\n",
    "        input_cat = torch.tensor(batch['cat'], dtype=torch.long).float().cuda()\n",
    "        target = torch.tensor(target).float().to(device)\n",
    "\n",
    "        predictions = model(input_site, input_cat).float()\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "        loss = loss_function(predictions, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "\n",
    "        history_train.append(loss.data.cpu().numpy())\n",
    "        if (idx+1)%5 == 0:\n",
    "            history_val.append(roc_auc(model, valid_df))\n",
    "            history_train_roc.append(roc_auc(model, train_df, prob = 0.3))\n",
    "        history_val.append(roc_auc(model, valid_df, prob = 0.1))\n",
    "        history_train_roc.append(roc_auc(model, train_df, prob = 0.01))\n",
    "        if (idx+1)%50==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history_val,label='val')\n",
    "            plt.plot(history_train_roc, label = 'train')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            print(f'val {history_train_roc[-1]}')\n",
    "            print(f'train {history_val[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.make_predictions_file(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9b90ETe5gOdBrOd9mhpam",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1q7pI8KwTPJ3fvsxzWbr_O5k-A8TRlvBl",
   "name": "catch_me.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
